{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCF1aKktr7wM"
      },
      "source": [
        "To train this agent, click **Runtime** > **Run all**. Make sure you've set your `WANDB_API_KEY`.\n",
        "\n",
        "<div class=\"align-center\">\n",
        "<a href=\"https://github.com/openpipe/art\"><img src=\"https://github.com/openpipe/art/raw/main/assets/ART_pill.png\" height=\"50\"></a>\n",
        "<a href=\"https://discord.gg/zbBHRUpwf4\"><img src=\"https://github.com/openpipe/art/raw/main/assets/Discord.png\" height=\"50\"></a>\n",
        "<a href=\"https://art.openpipe.ai\"><img src=\"https://github.com/openpipe/art/raw/main/assets/Documentation_pill.png\" height=\"50\"></a>\n",
        "\n",
        "Questions? Join the Discord and ask away! For feature requests or to leave a star, visit our [Github](https://github.com/openpipe/art).\n",
        "\n",
        "</div>\n",
        "\n",
        "<a href=\"https://art.openpipe.ai/\"><img src=\"https://github.com/openpipe/art/raw/main/assets/Header_separator.png\" height=\"5\"></a>\n",
        "\n",
        "This notebook shows how to train a Qwen 3 14B model to play 2048. It will demonstrate how to set up a multi-turn agent, how to train it, and how to evaluate it.\n",
        "\n",
        "Completions, metrics, and model checkpoints will be saved to Weights & Biases.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4Y5hOMer7wO"
      },
      "source": [
        "### Installation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "KXsOex6lr7wO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openpipe-art\n",
            "  Downloading openpipe_art-0.5.1-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: litellm==1.74.1 in /opt/anaconda3/lib/python3.13/site-packages (from openpipe-art) (1.74.1)\n",
            "Requirement already satisfied: openai<=1.99.1,>=1.65.5 in /opt/anaconda3/lib/python3.13/site-packages (from openpipe-art) (1.99.1)\n",
            "Requirement already satisfied: typer>=0.15.2 in /opt/anaconda3/lib/python3.13/site-packages (from openpipe-art) (0.20.0)\n",
            "Requirement already satisfied: weave>=0.51.51 in /opt/anaconda3/lib/python3.13/site-packages (from openpipe-art) (0.52.16)\n",
            "Requirement already satisfied: aiohttp>=3.10 in /opt/anaconda3/lib/python3.13/site-packages (from litellm==1.74.1->openpipe-art) (3.11.10)\n",
            "Requirement already satisfied: click in /opt/anaconda3/lib/python3.13/site-packages (from litellm==1.74.1->openpipe-art) (8.1.8)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /opt/anaconda3/lib/python3.13/site-packages (from litellm==1.74.1->openpipe-art) (0.28.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /opt/anaconda3/lib/python3.13/site-packages (from litellm==1.74.1->openpipe-art) (8.5.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /opt/anaconda3/lib/python3.13/site-packages (from litellm==1.74.1->openpipe-art) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /opt/anaconda3/lib/python3.13/site-packages (from litellm==1.74.1->openpipe-art) (4.23.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from litellm==1.74.1->openpipe-art) (2.10.3)\n",
            "Requirement already satisfied: python-dotenv>=0.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from litellm==1.74.1->openpipe-art) (1.1.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /opt/anaconda3/lib/python3.13/site-packages (from litellm==1.74.1->openpipe-art) (0.12.0)\n",
            "Requirement already satisfied: tokenizers in /opt/anaconda3/lib/python3.13/site-packages (from litellm==1.74.1->openpipe-art) (0.22.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2<4.0.0,>=3.1.2->litellm==1.74.1->openpipe-art) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.74.1->openpipe-art) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/lib/python3.13/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.74.1->openpipe-art) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/lib/python3.13/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.74.1->openpipe-art) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/lib/python3.13/site-packages (from jsonschema<5.0.0,>=4.22.0->litellm==1.74.1->openpipe-art) (0.22.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from openai<=1.99.1,>=1.65.5->openpipe-art) (4.7.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.13/site-packages (from openai<=1.99.1,>=1.65.5->openpipe-art) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/lib/python3.13/site-packages (from openai<=1.99.1,>=1.65.5->openpipe-art) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.13/site-packages (from openai<=1.99.1,>=1.65.5->openpipe-art) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.13/site-packages (from openai<=1.99.1,>=1.65.5->openpipe-art) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/lib/python3.13/site-packages (from openai<=1.99.1,>=1.65.5->openpipe-art) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.13/site-packages (from anyio<5,>=3.5.0->openai<=1.99.1,>=1.65.5->openpipe-art) (3.7)\n",
            "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.13/site-packages (from httpx>=0.23.0->litellm==1.74.1->openpipe-art) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.13/site-packages (from httpx>=0.23.0->litellm==1.74.1->openpipe-art) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/lib/python3.13/site-packages (from httpcore==1.*->httpx>=0.23.0->litellm==1.74.1->openpipe-art) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.5.0->litellm==1.74.1->openpipe-art) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /opt/anaconda3/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.5.0->litellm==1.74.1->openpipe-art) (2.27.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp>=3.10->litellm==1.74.1->openpipe-art) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp>=3.10->litellm==1.74.1->openpipe-art) (1.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp>=3.10->litellm==1.74.1->openpipe-art) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp>=3.10->litellm==1.74.1->openpipe-art) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp>=3.10->litellm==1.74.1->openpipe-art) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/anaconda3/lib/python3.13/site-packages (from aiohttp>=3.10->litellm==1.74.1->openpipe-art) (1.18.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /opt/anaconda3/lib/python3.13/site-packages (from importlib-metadata>=6.8.0->litellm==1.74.1->openpipe-art) (3.21.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/lib/python3.13/site-packages (from tiktoken>=0.7.0->litellm==1.74.1->openpipe-art) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /opt/anaconda3/lib/python3.13/site-packages (from tiktoken>=0.7.0->litellm==1.74.1->openpipe-art) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm==1.74.1->openpipe-art) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm==1.74.1->openpipe-art) (2.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from typer>=0.15.2->openpipe-art) (1.5.0)\n",
            "Requirement already satisfied: rich>=10.11.0 in /opt/anaconda3/lib/python3.13/site-packages (from typer>=0.15.2->openpipe-art) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from rich>=10.11.0->typer>=0.15.2->openpipe-art) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.13/site-packages (from rich>=10.11.0->typer>=0.15.2->openpipe-art) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.15.2->openpipe-art) (0.1.0)\n",
            "Requirement already satisfied: diskcache==5.6.3 in /opt/anaconda3/lib/python3.13/site-packages (from weave>=0.51.51->openpipe-art) (5.6.3)\n",
            "Requirement already satisfied: eval-type-backport in /opt/anaconda3/lib/python3.13/site-packages (from weave>=0.51.51->openpipe-art) (0.2.2)\n",
            "Requirement already satisfied: gql>=3.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from gql[aiohttp,requests]>=3.0.0->weave>=0.51.51->openpipe-art) (4.0.0)\n",
            "Requirement already satisfied: packaging>=21.0 in /opt/anaconda3/lib/python3.13/site-packages (from weave>=0.51.51->openpipe-art) (24.2)\n",
            "Requirement already satisfied: polyfile-weave in /opt/anaconda3/lib/python3.13/site-packages (from weave>=0.51.51->openpipe-art) (0.5.7)\n",
            "Requirement already satisfied: sentry-sdk<3.0.0,>=2.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from weave>=0.51.51->openpipe-art) (2.43.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,>=8.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from weave>=0.51.51->openpipe-art) (9.0.0)\n",
            "Requirement already satisfied: wandb>=0.17.1 in /opt/anaconda3/lib/python3.13/site-packages (from weave>=0.51.51->openpipe-art) (0.22.3)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.2 in /opt/anaconda3/lib/python3.13/site-packages (from gql>=3.0.0->gql[aiohttp,requests]>=3.0.0->weave>=0.51.51->openpipe-art) (3.2.7)\n",
            "Requirement already satisfied: backoff<3.0,>=1.11.1 in /opt/anaconda3/lib/python3.13/site-packages (from gql>=3.0.0->gql[aiohttp,requests]>=3.0.0->weave>=0.51.51->openpipe-art) (2.2.1)\n",
            "Requirement already satisfied: requests_toolbelt<2,>=1.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from gql[aiohttp,requests]>=3.0.0->weave>=0.51.51->openpipe-art) (1.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from wandb>=0.17.1->weave>=0.51.51->openpipe-art) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /opt/anaconda3/lib/python3.13/site-packages (from wandb>=0.17.1->weave>=0.51.51->openpipe-art) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /opt/anaconda3/lib/python3.13/site-packages (from wandb>=0.17.1->weave>=0.51.51->openpipe-art) (5.29.3)\n",
            "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.13/site-packages (from wandb>=0.17.1->weave>=0.51.51->openpipe-art) (6.0.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/anaconda3/lib/python3.13/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.17.1->weave>=0.51.51->openpipe-art) (4.0.7)\n",
            "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/anaconda3/lib/python3.13/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.17.1->weave>=0.51.51->openpipe-art) (4.0.0)\n",
            "Requirement already satisfied: abnf~=2.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from polyfile-weave->weave>=0.51.51->openpipe-art) (2.2.0)\n",
            "Requirement already satisfied: chardet>=5.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from polyfile-weave->weave>=0.51.51->openpipe-art) (5.2.0)\n",
            "Requirement already satisfied: cint>=1.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from polyfile-weave->weave>=0.51.51->openpipe-art) (1.0.0)\n",
            "Requirement already satisfied: fickling>=0.0.8 in /opt/anaconda3/lib/python3.13/site-packages (from polyfile-weave->weave>=0.51.51->openpipe-art) (0.1.4)\n",
            "Requirement already satisfied: graphviz>=0.20.1 in /opt/anaconda3/lib/python3.13/site-packages (from polyfile-weave->weave>=0.51.51->openpipe-art) (0.21)\n",
            "Requirement already satisfied: intervaltree>=2.4.0 in /opt/anaconda3/lib/python3.13/site-packages (from polyfile-weave->weave>=0.51.51->openpipe-art) (3.1.0)\n",
            "Requirement already satisfied: kaitaistruct~=0.10 in /opt/anaconda3/lib/python3.13/site-packages (from polyfile-weave->weave>=0.51.51->openpipe-art) (0.11)\n",
            "Requirement already satisfied: networkx>=2.6.3 in /opt/anaconda3/lib/python3.13/site-packages (from polyfile-weave->weave>=0.51.51->openpipe-art) (3.4.2)\n",
            "Requirement already satisfied: pdfminer.six<=20250506,>=20220524 in /opt/anaconda3/lib/python3.13/site-packages (from polyfile-weave->weave>=0.51.51->openpipe-art) (20250506)\n",
            "Requirement already satisfied: Pillow>=5.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from polyfile-weave->weave>=0.51.51->openpipe-art) (11.1.0)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /opt/anaconda3/lib/python3.13/site-packages (from polyfile-weave->weave>=0.51.51->openpipe-art) (80.9.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from pdfminer.six<=20250506,>=20220524->polyfile-weave->weave>=0.51.51->openpipe-art) (44.0.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /opt/anaconda3/lib/python3.13/site-packages (from cryptography>=36.0.0->pdfminer.six<=20250506,>=20220524->polyfile-weave->weave>=0.51.51->openpipe-art) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /opt/anaconda3/lib/python3.13/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six<=20250506,>=20220524->polyfile-weave->weave>=0.51.51->openpipe-art) (2.21)\n",
            "Requirement already satisfied: stdlib_list~=0.11.1 in /opt/anaconda3/lib/python3.13/site-packages (from fickling>=0.0.8->polyfile-weave->weave>=0.51.51->openpipe-art) (0.11.1)\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from intervaltree>=2.4.0->polyfile-weave->weave>=0.51.51->openpipe-art) (2.4.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /opt/anaconda3/lib/python3.13/site-packages (from tokenizers->litellm==1.74.1->openpipe-art) (1.1.2)\n",
            "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.74.1->openpipe-art) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.74.1->openpipe-art) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.74.1->openpipe-art) (1.2.0)\n",
            "Requirement already satisfied: typer-slim in /opt/anaconda3/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm==1.74.1->openpipe-art) (0.20.0)\n",
            "Downloading openpipe_art-0.5.1-py3-none-any.whl (166 kB)\n",
            "Installing collected packages: openpipe-art\n",
            "Successfully installed openpipe-art-0.5.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install openpipe-art"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqcaSOtFr7wN"
      },
      "source": [
        "### Environment Variables\n",
        "\n",
        "Later on in the notebook, we'll be creating a model that can automatically logs metrics to Weights & Biases and chat completions to Weave. In order to do so, you'll need to provide your Weights & Biases API key as an environment variable.\n",
        "\n",
        "*If you don't already have a W&B API key, you can get one [here](https://wandb.ai/home).*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "tyZkABN7r7wO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"WANDB_API_KEY\"] = \"5c15d7b3b0b4e432f23b799599edf9125439e358\"\n",
        "\n",
        "if not os.environ.get(\"WANDB_API_KEY\"):\n",
        "    raise ValueError(\"WANDB_API_KEY is required for inference, training, and logging to Weights & Biases.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epnsrA1Ar7wO",
        "tags": [
          "environment"
        ]
      },
      "source": [
        "### Agentic Environment\n",
        "\n",
        "<a name=\"Environment\"></a>\n",
        "\n",
        "ART allows your agent to learn by interacting with its environment. In this example, we'll create an environment in which the agent can play 2048.\n",
        "\n",
        "Feel free to read as much or as little of this section's code as you'd like. The important thing to understand is that we're defining the rules of this agent's environment. In many cases, this will already be defined by the task you're trying to solve, but if you need to define a custom environment, this is how you do it.\n",
        "\n",
        "NOTE: To speed up training, we're reducing the winning value from 2048 to 64, which in turn reduces the minimum number of moves to win.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SYWI9Ptlr7wO"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import string\n",
        "import xml.etree.ElementTree as ET\n",
        "from typing import Literal, Optional, TypedDict\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "WINNING_VALUE = 64\n",
        "\n",
        "\n",
        "# Class that keeps track of state for a single game of 2048\n",
        "class TwentyFortyEightGame(TypedDict):\n",
        "    id: str\n",
        "    board: list[list[Optional[int]]]\n",
        "\n",
        "\n",
        "# Randomly populates a cell on the board with a 2 or 4\n",
        "def populate_random_cell(game: TwentyFortyEightGame) -> None:\n",
        "    all_clear_coordinates = [\n",
        "        (i, j)\n",
        "        for i in range(len(game[\"board\"]))\n",
        "        for j in range(len(game[\"board\"][i]))\n",
        "        if game[\"board\"][i][j] is None\n",
        "    ]\n",
        "    random_clear_coordinates = random.choice(all_clear_coordinates)\n",
        "    # 90% chance to populate a 2, 10% chance to populate a 4\n",
        "    game[\"board\"][random_clear_coordinates[0]][random_clear_coordinates[1]] = (\n",
        "        2 if random.random() < 0.9 else 4\n",
        "    )\n",
        "\n",
        "\n",
        "# Generates a new game of 2048\n",
        "def generate_game(board_length: int = 4) -> TwentyFortyEightGame:\n",
        "    # random 6 character string\n",
        "    id = \"\".join(random.choices(string.ascii_letters + string.digits, k=6))\n",
        "    game = {\n",
        "        \"id\": id,\n",
        "        \"board\": [[None for _ in range(board_length)] for _ in range(board_length)],\n",
        "    }\n",
        "\n",
        "    # populate two random cells\n",
        "    populate_random_cell(game)\n",
        "    populate_random_cell(game)\n",
        "\n",
        "    return game\n",
        "\n",
        "\n",
        "# Renders the board in a human-readable format\n",
        "def render_board(game: TwentyFortyEightGame) -> str:\n",
        "    board = game[\"board\"]\n",
        "    # print something like this:\n",
        "    # _    | 2    | _    | 4\n",
        "    # 4    | 8    | 2    | 16\n",
        "    # 16   | 32   | 64   | 128\n",
        "    # _    | 2    | 2    | 4\n",
        "    # where _ is an empty cell\n",
        "\n",
        "    max_cell_width = max(\n",
        "        [len(str(cell)) for row in board for cell in row if cell is not None]\n",
        "    )\n",
        "\n",
        "    board_str = \"\"\n",
        "    for row in board:\n",
        "        # pad the cells with spaces to make them the same width\n",
        "        board_str += \"|\".join(\n",
        "            [\n",
        "                str(cell).rjust(max_cell_width)\n",
        "                if cell is not None\n",
        "                else \"_\".rjust(max_cell_width)\n",
        "                for cell in row\n",
        "            ]\n",
        "        )\n",
        "        board_str += \"\\n\"\n",
        "    return board_str\n",
        "\n",
        "\n",
        "# condense, privileging matches at the start of the sequence\n",
        "# sequences should be passed starting with cells that are the furthest in the direction in which the board is being condensed\n",
        "def condense_sequence(sequence: list[Optional[int]]) -> list[Optional[int]]:\n",
        "    condensed_sequence = []\n",
        "\n",
        "    gapless_sequence = [cell for cell in sequence if cell is not None]\n",
        "\n",
        "    i = 0\n",
        "    while i < len(gapless_sequence):\n",
        "        if (\n",
        "            i + 1 < len(gapless_sequence)\n",
        "            and gapless_sequence[i] == gapless_sequence[i + 1]\n",
        "        ):\n",
        "            condensed_sequence.append(gapless_sequence[i] * 2)\n",
        "            i += 2\n",
        "        else:\n",
        "            condensed_sequence.append(gapless_sequence[i])\n",
        "            i += 1\n",
        "\n",
        "    # pad the sequence with None at the end\n",
        "    return condensed_sequence + [None] * (4 - len(condensed_sequence))\n",
        "\n",
        "\n",
        "# Condenses the board in a given direction\n",
        "def condense_board(\n",
        "    game: TwentyFortyEightGame, direction: Literal[\"left\", \"right\", \"up\", \"down\"]\n",
        ") -> None:\n",
        "    if direction == \"left\":\n",
        "        for row in game[\"board\"]:\n",
        "            condensed_row = condense_sequence(row)\n",
        "            for i in range(len(row)):\n",
        "                row[i] = condensed_row[i]\n",
        "\n",
        "    if direction == \"right\":\n",
        "        for row in game[\"board\"]:\n",
        "            reversed_row = row[::-1]\n",
        "            # reverse the row before and after condensing\n",
        "            condensed_row = condense_sequence(reversed_row)[::-1]\n",
        "            for i in range(len(row)):\n",
        "                row[i] = condensed_row[i]\n",
        "\n",
        "    if direction == \"up\":\n",
        "        for col_index in range(len(game[\"board\"][0])):\n",
        "            column = [row[col_index] for row in game[\"board\"]]\n",
        "\n",
        "            condensed_column = condense_sequence(column)\n",
        "            for row_index in range(len(column)):\n",
        "                game[\"board\"][row_index][col_index] = condensed_column[row_index]\n",
        "\n",
        "    if direction == \"down\":\n",
        "        for col_index in range(len(game[\"board\"][0])):\n",
        "            column = [row[col_index] for row in game[\"board\"]]\n",
        "            reversed_column = column[::-1]\n",
        "            condensed_column = condense_sequence(reversed_column)[::-1]\n",
        "            for row_index in range(len(column)):\n",
        "                game[\"board\"][row_index][col_index] = condensed_column[row_index]\n",
        "\n",
        "\n",
        "# Applies an agent move to the game board\n",
        "def apply_agent_move(game: TwentyFortyEightGame, move_xml: str) -> None:\n",
        "    direction = None\n",
        "    # parse the move\n",
        "    try:\n",
        "        root = ET.fromstring(move_xml)\n",
        "        direction = root.text\n",
        "    except Exception:\n",
        "        raise ValueError(\"Invalid xml\")\n",
        "\n",
        "    if direction not in [\"left\", \"right\", \"up\", \"down\"]:\n",
        "        raise ValueError(\"Invalid direction\")\n",
        "\n",
        "    condense_board(game, direction)\n",
        "\n",
        "    populate_random_cell(game)\n",
        "\n",
        "\n",
        "# Returns the maximum cell value on the board\n",
        "def max_cell_value(game: TwentyFortyEightGame) -> int:\n",
        "    return max([cell for row in game[\"board\"] for cell in row if cell is not None])\n",
        "\n",
        "\n",
        "# Returns True if the game is finished\n",
        "def check_game_finished(game: TwentyFortyEightGame) -> bool:\n",
        "    if max_cell_value(game) >= WINNING_VALUE:\n",
        "        return True\n",
        "\n",
        "    # check if any cell is empty\n",
        "    if any(cell is None for row in game[\"board\"] for cell in row):\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "\n",
        "# Returns the sum of all the cell values on the board\n",
        "def total_board_value(game: TwentyFortyEightGame) -> int:\n",
        "    return sum([cell for row in game[\"board\"] for cell in row if cell is not None])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwPZPzvbr7wP"
      },
      "source": [
        "### Creating a Model\n",
        "\n",
        "Now that we've defined the rules of our environment, we can create a model that will learn to play 2048. We'll use a Qwen 3 14B model for this example. The `name` parameter will be associated with a wandb run, and the `base_model` parameter is the model that we'll be training a LoRA on top of. `ServerlessBackend` hooks into Serverless RL through W&B Training to autoscale GPUs as your job progresses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "tQhtIZFOr7wP"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "import art\n",
        "from art.serverless.backend import ServerlessBackend\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "random.seed(42)\n",
        "\n",
        "# Declare the model\n",
        "model = art.TrainableModel(\n",
        "    name=\"agent-001\",\n",
        "    project=\"2048\",\n",
        "    base_model=\"OpenPipe/Qwen3-14B-Instruct\",\n",
        ")\n",
        "\n",
        "# Initialize the server\n",
        "# Training and inference will run on Weights & Biases servers\n",
        "backend = ServerlessBackend()\n",
        "\n",
        "# Register the model with the Serverless Backend (sets up logging, inference, and training)\n",
        "await model.register(backend)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8DY7vMir7wP",
        "tags": [
          "rollout"
        ]
      },
      "source": [
        "### Defining a Rollout\n",
        "\n",
        "<a name=\"Rollout\"></a>\n",
        "\n",
        "A rollout is a single episode of an agent performing its task. It generates one or more trajectories, which are lists of messages and choices.\n",
        "\n",
        "In this example, the rollout function generates a game of 2048, and the agent plays it until the game is finished. It then returns a trajectory which contains all the `system` and `user` messages presented to the agent, as well as all the `choices` that the agent made.\n",
        "\n",
        "When the game is finished the `reward` for the agent's performance is calculated based on the highest cell value on the board, which is then assigned to the trajectory.\n",
        "\n",
        "This rollout function will be called many times in parallel during each step of the training loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "tXKhFp_Or7wP"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "import requests\n",
        "import weave\n",
        "from openai import AsyncOpenAI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "import art\n",
        "\n",
        "weave.init(model.project, settings={\"print_call_link\": False})\n",
        "\n",
        "\n",
        "\n",
        "class Scenario2048(BaseModel):\n",
        "    step: int\n",
        "\n",
        "\n",
        "@weave.op\n",
        "@art.retry(exceptions=(requests.ReadTimeout))\n",
        "async def rollout(model: art.Model, scenario: Scenario2048) -> art.Trajectory:\n",
        "    client = AsyncOpenAI(\n",
        "        base_url=model.inference_base_url,\n",
        "        api_key=model.inference_api_key,\n",
        "    )\n",
        "    game = generate_game()\n",
        "\n",
        "    move_number = 0\n",
        "\n",
        "    trajectory = art.Trajectory(\n",
        "        messages_and_choices=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are an excellent 2048 player. Always choose the move most likely to lead to combine cells to eventually reach the number 2048. Optional moves are 'left', 'right', 'up', 'down'. Return your move as an XML object with a single property 'move', like so: <move>left</move>\",\n",
        "            }\n",
        "        ],\n",
        "        metadata={\n",
        "            \"game_id\": game[\"id\"],\n",
        "            \"notebook-id\": \"2048\",\n",
        "            \"step\": scenario.step,\n",
        "        },\n",
        "        reward=0,\n",
        "    )\n",
        "\n",
        "    while True:\n",
        "        trajectory.messages_and_choices.append(\n",
        "            {\"role\": \"user\", \"content\": render_board(game)}\n",
        "        )\n",
        "\n",
        "        try:\n",
        "            messages = trajectory.messages()\n",
        "            chat_completion = await client.chat.completions.create(\n",
        "                max_completion_tokens=128,\n",
        "                messages=messages,\n",
        "                model=model.get_inference_name(),\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(\"caught exception generating chat completion\", e)\n",
        "            raise e\n",
        "\n",
        "        choice = chat_completion.choices[0]\n",
        "        content = choice.message.content\n",
        "        assert isinstance(content, str)\n",
        "        trajectory.messages_and_choices.append(choice)\n",
        "\n",
        "        try:\n",
        "            apply_agent_move(game, content)\n",
        "            move_number += 1\n",
        "        except ValueError:\n",
        "            trajectory.reward = -1\n",
        "            break\n",
        "\n",
        "        if check_game_finished(game):\n",
        "            max_value = max_cell_value(game)\n",
        "            board_value = total_board_value(game)\n",
        "            trajectory.metrics[\"max_value\"] = max_value\n",
        "            trajectory.metrics[\"board_value\"] = board_value\n",
        "            trajectory.metrics[\"move_number\"] = move_number\n",
        "\n",
        "            # try to get as close to the winning value as possible\n",
        "            # otherwise, try to maximize number of high cells on board\n",
        "            # but above all else: WIN THE GAME!\n",
        "            if max_value < WINNING_VALUE:\n",
        "                # scale max value logarithmically between 0 for 2 and 1 for WINNING_VALUE\n",
        "                max_value_reward = (math.log(max_value, 2) - 1) / (\n",
        "                    math.log(WINNING_VALUE, 2) - 1\n",
        "                )\n",
        "                # scale board value logarithmically between 0 for 2 * 16 and 1 for WINNING_VALUE * 16\n",
        "                board_value_reward = (math.log(board_value, 2) - 1) / (\n",
        "                    math.log(WINNING_VALUE * 16, 2) - 1\n",
        "                )\n",
        "                # combine the two rewards, with max value having a higher weight\n",
        "                trajectory.reward = max_value_reward + (board_value_reward * 0.2)\n",
        "            else:\n",
        "                # double reward if the agent wins\n",
        "                trajectory.reward = 2\n",
        "            break\n",
        "\n",
        "    return trajectory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr8DzLI4r7wP",
        "tags": [
          "loop"
        ]
      },
      "source": [
        "<a name=\"Loop\"></a>\n",
        "\n",
        "### Training Loop\n",
        "\n",
        "The training loop is where the magic happens. For each of the 20 steps defined below, the rollout function will be called 18 times in parallel. This means that 18 games will be played at once. Each game will produce a trajectory, which will be used to update the model.\n",
        "\n",
        "The `gather` step will wait for all of the trajectories to be generated, then it will delete all but the best-performing and most recent checkpoints and train the model on the new trajectories. Inference will be blocked until the training is complete.\n",
        "\n",
        "While training executes, track your agent's metrics and traces in [W&B](https://wandb.ai/home).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "o-p5jaGur7wP"
      },
      "outputs": [],
      "source": [
        "for i in range(await model.get_step(), 20):\n",
        "    train_groups = await art.gather_trajectory_groups(\n",
        "        (\n",
        "            art.TrajectoryGroup(rollout(model, Scenario2048(step=i)) for _ in range(18))\n",
        "            for _ in range(1)\n",
        "        ),\n",
        "        pbar_desc=\"gather\",\n",
        "        max_exceptions=18,\n",
        "    )\n",
        "    await model.delete_checkpoints('train/reward')\n",
        "    await model.train(\n",
        "        train_groups,\n",
        "        config=art.TrainConfig(learning_rate=1e-5),\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmSndgphr7wP"
      },
      "source": [
        "### Using the Model\n",
        "\n",
        "Just like that, you've trained an agent to play 2048! Now it's time to use your model outside of ART, in the wild! The easiest way to do that is to create an OpenAI client and make a chat completion request to W&B Inference, where it's already deployed ðŸ˜Š.\n",
        "\n",
        "Check out the code below for small demo of the model you just trained playing 2048!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "T5mMSMJ9r7wP",
        "outputId": "febd4699-83d3-4c07-e67e-5acdaf34d345"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "step 20 deployed as wandb-artifact:///zperfet/2048/agent-001:step20\n",
            "\n",
            "move 10\n",
            "board:\n",
            "8|4|2|_\n",
            "4|_|_|_\n",
            "2|_|_|_\n",
            "_|2|_|_\n",
            "\n",
            "agent move: <move>up</move>\n",
            "updated board:\n",
            "8|4|2|_\n",
            "4|2|2|_\n",
            "2|_|_|_\n",
            "_|_|_|_\n",
            "\n",
            "\n",
            "move 20\n",
            "board:\n",
            "16| 8| _| _\n",
            " 8| 2| _| _\n",
            " 4| 2| _| _\n",
            " _| _| 2| _\n",
            "\n",
            "agent move: <move>up</move>\n",
            "updated board:\n",
            "16| 8| 2| 2\n",
            " 8| 4| _| _\n",
            " 4| _| _| _\n",
            " _| _| _| _\n",
            "\n",
            "\n",
            "move 30\n",
            "board:\n",
            "32| 2| _| 2\n",
            " 8| 8| 2| _\n",
            " 4| 2| _| _\n",
            " 2| _| _| _\n",
            "\n",
            "agent move: <move>up</move>\n",
            "updated board:\n",
            "32| 2| 2| 2\n",
            " 8| 8| _| _\n",
            " 4| 2| _| 2\n",
            " 2| _| _| _\n",
            "\n",
            "\n",
            "move 40\n",
            "board:\n",
            "32|16| 2| _\n",
            "16| 4| 2| _\n",
            " 8| 4| _| _\n",
            " 2| _| _| _\n",
            "\n",
            "agent move: <move>up</move>\n",
            "updated board:\n",
            "32|16| 4| _\n",
            "16| 8| 4| _\n",
            " 8| _| _| _\n",
            " 2| _| _| _\n",
            "\n",
            "\n",
            "move 50\n",
            "board:\n",
            "32|16| 8| 2\n",
            "16| 8| 2| 4\n",
            "16| 2| 2| _\n",
            " 4| _| _| _\n",
            "\n",
            "agent move: <move>up</move>\n",
            "updated board:\n",
            "32|16| 8| 2\n",
            "32| 8| 4| 4\n",
            " 4| 2| 2| _\n",
            " _| _| _| _\n",
            "\n",
            "game finished in 52 moves\n",
            "game won! ðŸ’ª\n",
            "final board:\n",
            "\n",
            "64|16|16| 2\n",
            " 4| 8| 2| 2\n",
            " _| 4| _| _\n",
            " _| _| _| _\n",
            "\n",
            "max value: 64\n",
            "board value: 118\n"
          ]
        }
      ],
      "source": [
        "last_step = await model.get_step()\n",
        "\n",
        "deployed_inference_model_name = f\"{model.get_inference_name()}:step{last_step}\"\n",
        "\n",
        "print(f\"step {last_step} deployed as {deployed_inference_model_name}\")\n",
        "\n",
        "client = AsyncOpenAI(\n",
        "    base_url=model.inference_base_url,\n",
        "    api_key=model.inference_api_key,\n",
        ")\n",
        "\n",
        "game = generate_game()\n",
        "move_number = 0\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are an excellent 2048 player. Always choose the move most likely to lead to combine cells to eventually reach the number 2048. Optional moves are 'left', 'right', 'up', 'down'. Return your move as an XML object with a single property 'move', like so: <move>left</move>\",\n",
        "    },\n",
        "]\n",
        "\n",
        "while not check_game_finished(game):\n",
        "    rendered_board = render_board(game)\n",
        "    messages.append({\"role\": \"user\", \"content\": rendered_board})\n",
        "\n",
        "    try:\n",
        "        content = (await client.chat.completions.create(\n",
        "            model=deployed_inference_model_name,\n",
        "            messages=messages,\n",
        "        )).choices[0].message.content\n",
        "    except Exception as e:\n",
        "        print(\"caught exception generating chat completion\", e)\n",
        "        raise e\n",
        "\n",
        "    messages.append({\"role\": \"assistant\", \"content\": content})\n",
        "\n",
        "    try:\n",
        "        apply_agent_move(game, content)\n",
        "        move_number += 1\n",
        "    except ValueError:\n",
        "        raise ValueError(f\"Invalid move on move {move_number}: {content}\")\n",
        "\n",
        "    # print the board every 10 moves\n",
        "    if move_number % 10 == 0:\n",
        "        print(f\"\\nmove {move_number}\")\n",
        "        print(f\"board:\\n{rendered_board}\")\n",
        "        print(f\"agent move: {content}\")\n",
        "        print(f\"updated board:\\n{render_board(game)}\")\n",
        "\n",
        "\n",
        "print(f\"game finished in {move_number} moves\")\n",
        "\n",
        "max_value = max_cell_value(game)\n",
        "board_value = total_board_value(game)\n",
        "\n",
        "if max_value >= WINNING_VALUE:\n",
        "    print(\"game won! ðŸ’ª\")\n",
        "else:\n",
        "    print(\"game lost! ðŸ˜¢\")\n",
        "\n",
        "\n",
        "print(f\"final board:\\n\\n{render_board(game)}\")\n",
        "print(f\"max value: {max_value}\")\n",
        "print(f\"board value: {board_value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4m3eqX_Vr7wQ"
      },
      "source": [
        "<div class=\"align-center\">\n",
        "<a href=\"https://github.com/openpipe/art\"><img src=\"https://github.com/openpipe/art/raw/main/assets/ART_pill.png\" height=\"50\"></a>\n",
        "<a href=\"https://discord.gg/zbBHRUpwf4\"><img src=\"https://github.com/openpipe/art/raw/main/assets/Discord.png\" height=\"50\"></a>\n",
        "<a href=\"https://openpipe.ai/blog/art-e-mail-agent\"><img src=\"https://github.com/openpipe/art/raw/main/assets/ART_E_pill.png\" height=\"50\"></a>\n",
        "\n",
        "Congratulations! Now that you've seen a basic notebook, try training a more realistic [email search agent](https://colab.research.google.com/github/openpipe/art-notebooks/blob/main/examples/art-e.ipynb).\n",
        "\n",
        "If you have questions along the way, join the Discord and ask away! For feature requests or to leave a star, visit our [Github](https://github.com/openpipe/art).\n",
        "\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nazJe5pZq8I"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
